![Header](https://github.com/matveysofie/algoritms/blob/main/assets/HEADER.jpg)

<p align="center"> 
    <samp>ðŸ§¾ Complexity of algorithms. Sorting</samp>
</p>
<hr>

![Python](https://img.shields.io/badge/-Python-ececec?style=for-the-badge&logo=python&logoColor=2c3e50)

<p align="center"> 
    <samp>Complexity of algorithms</samp>
</p>

<p>
O(1) is constant complexity when the execution time does not depend on the size of the input data. For example, getting an element by index in an array; <br> <hr>
O(log n) is the logarithmic complexity when the execution time grows slower than the size of the input data. For example, binary search in a sorted array;<br> <hr>
O(n) is a linear complexity when the execution time increases in proportion to the size of the input data. For example, passing through all the elements in the array;<br> <hr>
O(n log n) is the complexity of "quick sort" when the execution time grows faster than linear, but slower than quadratic. For example, quick sort;<br> <hr>
O(n^2) is the quadratic complexity when the execution time increases proportionally to the square of the input data size. For example, sorting by inserts;<br> <hr>
O(n^3) is the cubic complexity when the execution time grows proportionally to the cube of the input data size. For example, matrix multiplication;<br> <hr>
O(2^n) is exponential complexity when the execution time grows faster than any polynomial complexity. For example, iterating over all subsets of the set;<br> <hr>
O(n!) is factorial complexity when the execution time grows faster than exponential complexity. For example, iterating through all permutations of array elements.<br>